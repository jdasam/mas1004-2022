{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004-2022/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7oN9TOC3WQr"
      },
      "source": [
        "# Assignment 2: Image Classification\n",
        "- In this assignment you have to train image classification model with __your own data__\n",
        "- You have to submit 1) a report, 2) code and 3) data\n",
        "  1. Report in free format (submit in PDF)\n",
        "    - 1) Introduce why you selected these four categories\n",
        "    - 2) Describe the very first result of training the model, especially about the error cases\n",
        "    - 3) Explain your criteria for data cleaning\n",
        "    - Your submission would be evalulated mainly with the report\n",
        "    - Please include the plot figures that were generated during the experiment in your report\n",
        "    - DO NOT INCLUDE MORE THAN FIVE Experiments in your report\n",
        "  2. code (submit in ipynb)\n",
        "  3. data (submit in zip files)\n",
        "\n",
        "- Evaluation Criteria:\n",
        "  1. How well did you apply the knowledge from the class\n",
        "  2. How well did you improve the result\n",
        "  3. How well did you analyze the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfl16FmrrY82"
      },
      "source": [
        "## 0. Install Library and Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igvvejFk2qRW"
      },
      "outputs": [],
      "source": [
        "!pip install -q jmd_imagescraper\n",
        "\n",
        "import random\n",
        "import shutil\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from jmd_imagescraper.core import duckduckgo_search\n",
        "from PIL import Image\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XypX1h6KrY83"
      },
      "source": [
        "## 1. Configure Settings\n",
        "- 1) Select the storage type\n",
        "  - Since Colab storage is volatile, your image dataset or model would disappear after the session ends.\n",
        "  - There are two options to save the data permanently:\n",
        "    1. Save your data in your local computer by downloading it from Colab. select `SAVE_TYP='local'`\n",
        "    2. Save your data in your Google Drive storage. select `SAVE_TYP='google_drive'`\n",
        "  - If you are running on your local computer, use `SAVE_TYP='local'`\n",
        "- 2) Select Number of images you want to collect\n",
        "  - `NUM_IMG` will define the number of image per category for crawling\n",
        "  - `100<=NUM_IMG<=500` of your choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9U-Byv9rY83"
      },
      "outputs": [],
      "source": [
        "# SAVE_TYP = 'local'\n",
        "SAVE_TYP = 'google_drive'\n",
        "NUM_IMG = 100 # This will define how many images you will download\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "  if SAVE_TYP == 'local': # if you selected to save it in local\n",
        "    from google.colab import files\n",
        "  else:\n",
        "    from google.colab import drive # if you selected to save it in your Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    GGL_DIR = Path('/content/drive/MyDrive/Data_AI_Assignment2/')\n",
        "    GGL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "IMG_DIR = Path('images')\n",
        "if IN_COLAB and SAVE_TYP==\"google_drive\":\n",
        "  PLOT_DIR = GGL_DIR / \"plots/\"\n",
        "else:\n",
        "  PLOT_DIR = Path('plots')\n",
        "PLOT_DIR.mkdir(exist_ok=True)\n",
        "DEL_DIR = IMG_DIR / 'deleted'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-PA5Xi536L2"
      },
      "source": [
        "## Problem 1: Collect Data (20 pts)\n",
        "- You have to select 4 image categories of your own choice\n",
        "- The selected categories will be used as an image class for the classification model\n",
        "- Evaluation:\n",
        "    - If you select four categories that does not make error on the code, you will get 10 pts\n",
        "    - If the selected 4 categories and collected images are reasonable for training an image classification model, you will get another 5 pts\n",
        "    - Remaining 5 pts will be evaluated based on how interesting is your choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab8_KzBs3gi9"
      },
      "outputs": [],
      "source": [
        "def configure_image_categories():\n",
        "  '''\n",
        "  input: None\n",
        "  output: List of strings that contains 4 classes\n",
        "\n",
        "  example: image_keywords = ['football', 'basketball', 'baseball', 'volleyball']\n",
        "  '''\n",
        "  # TODO: Complete the function\n",
        "  image_keywords =  ['football', 'basketball', 'baseball', 'volleyball']\n",
        "  return image_keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF5BKi2Gu2gB"
      },
      "source": [
        "## Image Crawling\n",
        "- Following code will automatically crawl the images with the keyword you have choosen\n",
        "- After running it, it will automatically split train and valid to ratio of 8:2\n",
        "  - Training data will be located `images/train`\n",
        "  - Validation data will be locatd `images/valid`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKr6IdVFG0TN"
      },
      "source": [
        "#### Pre-defined Functions (run it without opening it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7IKt6sbrY86"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "You don't have to change this cell\n",
        "'''\n",
        "\n",
        "def get_image_using_duckduckgo(img_dir:Path, image_types: list, num_img:int):\n",
        "  for typ in image_types:\n",
        "    duckduckgo_search(img_dir, typ, typ, max_results=NUM_IMG)\n",
        "    typ_dir = img_dir / typ\n",
        "\n",
        "def split_train_and_valid(img_dir, image_types, random_seed=0):\n",
        "  random.seed(0)\n",
        "  valid_indices = random.sample(range(NUM_IMG), NUM_IMG//5)\n",
        "  image_keywords = [child.name for child in img_dir.iterdir() if child.is_dir()]\n",
        "  for typ in image_keywords:\n",
        "    typ_dir = img_dir / typ\n",
        "    train_dir = img_dir / 'train' / typ\n",
        "    test_dir = img_dir / 'test' / typ\n",
        "    train_dir.mkdir(parents=True, exist_ok=True)\n",
        "    test_dir.mkdir(parents=True, exist_ok=True)\n",
        "    img_files = list(typ_dir.rglob('*.jpg'))\n",
        "    valid_imgs = [img_files[i] for i in valid_indices]\n",
        "    for fn in valid_imgs:\n",
        "      shutil.move(fn, test_dir/fn.name)\n",
        "    img_files = list(typ_dir.rglob('*.jpg'))\n",
        "    for fn in img_files:\n",
        "      shutil.move(fn, train_dir/fn.name)\n",
        "    os.rmdir(typ_dir)\n",
        "\n",
        "def save_fig_with_date(figname):\n",
        "  plt.savefig(PLOT_DIR/f\"{figname}_{'_'.join(time.ctime().split(' ')[1:4])}.png\")\n",
        "\n",
        "def file_name_with_date(filename):\n",
        "  filename = Path(filename)\n",
        "  return f\"{filename.stem}_{'_'.join(time.ctime().split(' ')[1:4])}{filename.suffix}\"\n",
        "\n",
        "def save_file(fn):\n",
        "  if IN_COLAB: # If you are running this notebook on Colab \n",
        "    if SAVE_TYP == 'local': # if you selected to save it in local\n",
        "      files.download(fn)   # download the file to your local computer \n",
        "    else:\n",
        "      shutil.copy(fn, GGL_DIR)  # copy the file to your google drive\n",
        "\n",
        "def plot_random_sampled_images(img_dir, ncols=4, nrows=5,random_seed=0):\n",
        "  list_of_image_files = list(img_dir.rglob(\"*.jpg\"))\n",
        "  random.seed(random_seed)\n",
        "  random.shuffle(list_of_image_files)\n",
        "  plt.figure(figsize=(ncols*5,nrows*4))\n",
        "  for i in range(ncols*nrows):\n",
        "    fname = list_of_image_files[i]\n",
        "    image = Image.open(fname)\n",
        "    plt.subplot(nrows,ncols, i+1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('/'.join(str(fname.parent).split('/')[-2:]))\n",
        "    plt.axis('off')\n",
        "  save_fig_with_date(\"dataset_check\") # save figure as png in PLOT_DIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyAvAZuP66tK"
      },
      "source": [
        "### Download or Unzip\n",
        "- If this is your first time to download the dataset, it will automatically download the images fro duckduckgo search\n",
        "- If you already ran the crawling code and have `image_data.zip` file in your local or google drive, you can upload it to the current Colab storage and unzip it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPyQP4yF3V-R"
      },
      "outputs": [],
      "source": [
        "image_types = configure_image_categories()\n",
        "assert len(image_types)==4, \"The length of image types has to be 4\"\n",
        "assert all( isinstance(typ, str) for typ in image_types), \"Every element of image_types has to be string\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF7osSmOempf"
      },
      "source": [
        "- If you want to delete every file in the `images/`, you can run following code\n",
        "  - `!rm -rf images/`\n",
        "  - It will forcely remove every file and directory in images. So please be careful when using it\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jfAqFJe1e8dy"
      },
      "outputs": [],
      "source": [
        "# delete the images/ folder if you want to re-compose your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t8F2WLoe8wK"
      },
      "source": [
        "- Following code will download the dataset or unzip the pre-saved zip files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFtebCv_rY87"
      },
      "outputs": [],
      "source": [
        "if not IMG_DIR.exists(): # If there is no image directory\n",
        "  if Path(\"image_data_cleaned.zip\").exists(): # if there is already cleaned dataset\n",
        "    print(\"Extracting image_data_cleaned.zip\")\n",
        "    os.system(\"unzip -q image_data_cleaned.zip\") # unzip image_data_cleaned.zip\n",
        "  elif IN_COLAB and SAVE_TYP == \"google_drive\" and (GGL_DIR/\"image_data_cleaned.zip\").exists(): # if there is already cleaned dataset on GD\n",
        "    print(\"Extracting image_data_cleaned.zip from Google Drive\")\n",
        "    shutil.copy(str(GGL_DIR/\"image_data_cleaned.zip\"), \"/content/\") # copy it to colab storage\n",
        "    os.system(\"unzip -q image_data_cleaned.zip\") # and unzip it\n",
        "  elif Path(\"image_data.zip\").exists(): # If image_data.zip file exists\n",
        "    print(\"Extracting image_data.zip\")\n",
        "    os.system(\"unzip -q image_data.zip\") # Unzip the zip file\n",
        "  elif IN_COLAB and SAVE_TYP == \"google_drive\" and (GGL_DIR/\"image_data.zip\").exists():\n",
        "    print(\"Extracting image_data.zip from Google Drive\")\n",
        "    shutil.copy(str(GGL_DIR/\"image_data.zip\"), \"/content/\")\n",
        "    os.system(\"unzip -q image_data.zip\")\n",
        "  else: # If there is no image directory and also no image_data.zip\n",
        "    print(\"Downloading images from DuckDuckGo\")\n",
        "    get_image_using_duckduckgo(IMG_DIR, image_types, NUM_IMG) # Download image files\n",
        "    split_train_and_valid(IMG_DIR, image_types) # Split train and valid into different directories\n",
        "    os.system(f\"zip -rq image_data.zip {IMG_DIR}\") # Make zip file that contains images directory\n",
        "    save_file(\"image_data.zip\")\n",
        "else:\n",
        "  print(f\"IMG_DIR ({IMG_DIR}) already exists\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMCVfaR0rY89"
      },
      "source": [
        "### Plot your Dataset\n",
        "- It is always important to check your dataset in detail\n",
        "- Run the script below and see the result\n",
        "  - The figure will automatically saved as png with current time to `PLOT_DIR`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cukbNQprY89"
      },
      "outputs": [],
      "source": [
        "plot_random_sampled_images(IMG_DIR, ncols=4, nrows=5, random_seed=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFg4_4AsyAFE"
      },
      "source": [
        "## Problem 2: Report the first training result (20 pts)\n",
        "- You don't have to change the code for Problem 2 if you have made the correct dataset on Problem 1\n",
        "- Evaluation: How well did you explain the result of your first training on Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pou71N2E3318"
      },
      "source": [
        "### DataBlock\n",
        "Class that can feed data in a right format to fastai model.\n",
        "* *blocks*: type of input/labels. \n",
        "  * *(ImageBlock, CategoryBlock)* means that input is image and label is categorical value\n",
        "* *get_items*: a function to load item from storage. \n",
        "  * *get_image_files* is a fastai function that get lists of image files in a given directory\n",
        "* *splitter*: a function to split train and validation\n",
        "  * *GrandparentSplitter* splits dataset by its Grandparent directory (parent directory of parent directory) name.\n",
        "* *get_y*: a function to get label \n",
        "  * *parent_label* means to use name of parent directory of item as the label\n",
        "* *item_tfms*: item transformation. How to transform the loaded item before feeding it to a neural network model\n",
        "  * *Resize* is to resize entire image into square of certain size. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRTmdt7a3qO1"
      },
      "outputs": [],
      "source": [
        "class ImageSet:\n",
        "  def __init__(self, path_dir, file_types=['jpg', 'png'], transform=None):\n",
        "    self.path = Path(path_dir)\n",
        "    self.image_fns = sorted(item for y in [list(self.path.rglob(f'*.{x}')) for x in file_types] for item in y) \n",
        "    self.classes = sorted(list(set([x.parent.name for x in self.image_fns])))\n",
        "    self.cls2idx = {k: i for i, k in enumerate(self.classes)}\n",
        "    self.transform = transforms.Compose([\n",
        "                        transforms.Resize(256),\n",
        "                        transforms.CenterCrop(224),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.image_fns)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    img_path = self.image_fns[idx]\n",
        "    img = self.transform(Image.open(img_path).convert('RGB'))\n",
        "    cls = img_path.parent.name\n",
        "    return img, self.cls2idx[cls]\n",
        "\n",
        "trainset = ImageSet(IMG_DIR/'train')\n",
        "testset = ImageSet(IMG_DIR/'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxDwf939rY8-"
      },
      "source": [
        "Check the Batch result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSM9ZQVMCxky"
      },
      "outputs": [],
      "source": [
        "tensor2pil = transforms.Compose([\n",
        "    transforms.Normalize(mean=[0, 0, 0], std=[4.3668, 4.4643, 4.4444]),\n",
        "    transforms.Normalize(mean=[-0.485, -0.456, -0.406], std=[1, 1, 1]),\n",
        "    transforms.ToPILImage()\n",
        "])\n",
        "\n",
        "\n",
        "def show_batch(dataloader, ncols=4, nrows=5, random_seed=0):\n",
        "  torch.manual_seed(random_seed)\n",
        "  images, labels = next(iter(dataloader))\n",
        "  plt.figure(figsize=(ncols*5,nrows*4))\n",
        "  for i in range(ncols*nrows):\n",
        "    plt.subplot(nrows, ncols, i+1)\n",
        "    pil_img = tensor2pil(images[i])\n",
        "    plt.imshow(pil_img)\n",
        "    plt.title(trainset.classes[labels[i]])\n",
        "    plt.axis('off')\n",
        "\n",
        "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(testset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5pyF7_kQCxky"
      },
      "outputs": [],
      "source": [
        "show_batch(train_loader, random_seed=0)\n",
        "save_fig_with_date(\"dls_default_train_batch\") # Don't forget to always save the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6ENxoM98mI_"
      },
      "source": [
        "### Train the first model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypj6fWaOCxky"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "class Trainer:\n",
        "  def __init__(self, model, train_loader, valid_loader):\n",
        "    self.model = model\n",
        "    self.train_loader = train_loader\n",
        "    self.valid_loader = valid_loader\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.model.to(self.device)\n",
        "    self.criterion = nn.NLLLoss()\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "    self.best_loss = np.inf\n",
        "    self.best_acc = 0.0\n",
        "    self.best_epoch = 0\n",
        "    self.best_model = None\n",
        "    self.train_losses = []\n",
        "    self.valid_losses = []\n",
        "    self.train_accs = []\n",
        "    self.valid_accs = []\n",
        "\n",
        "  def fine_tune(self, num_epochs):\n",
        "    self.model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "      for batch in self.train_loader:\n",
        "        images, labels = batch\n",
        "        images, labels = images.to(self.device), labels.to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        outputs = self.model(images)\n",
        "        loss = self.criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "trainer = Trainer(model, train_loader, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2N7gHmAVJ-il"
      },
      "outputs": [],
      "source": [
        "learn = cnn_learner(dls, resnet18, metrics=error_rate) # Define learn\n",
        "learn.fine_tune(20) # This will run fine tuning\n",
        "save_name =file_name_with_date(\"1st_learn.pkl\") # \n",
        "learn.export(save_name) # save learn result as pkl file\n",
        "save_file(save_name) # move file to local or google drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwPuTBv-8pLu"
      },
      "source": [
        "#### Load Model\n",
        "- You can load the pkl learn object by:\n",
        "`learn = load_learner(save_name)`\n",
        "- Since the `learn.export()` only export model parameters and optimizer parameters, it will lose `learn.recorder` object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffZJr2_y8i-l"
      },
      "outputs": [],
      "source": [
        "loaded_learner = load_learner(save_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLyxgsU49CmB"
      },
      "source": [
        "### Check the train result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zJWJZLurY8_"
      },
      "outputs": [],
      "source": [
        "learn.recorder.plot_loss()\n",
        "save_fig_with_date(\"loss\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FS9LBteNKEr5"
      },
      "outputs": [],
      "source": [
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix()\n",
        "save_fig_with_date(\"confusion\")\n",
        "interp.plot_top_losses(10, ncols=1)\n",
        "save_fig_with_date(\"top_losses\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QD9EQFVHjkC"
      },
      "outputs": [],
      "source": [
        "interp.print_classification_report()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ge0iWVqJHq8C"
      },
      "outputs": [],
      "source": [
        "interp.most_confused()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iboSMkXAvRGu"
      },
      "source": [
        "## Problem 3: Clean your Dataset (30 Pts)\n",
        "- The goal of data cleaning is to make sure that your dataset consists of images with specific characteristics you want.\n",
        "\n",
        "- Cell below is the modified version of `jmd_imagescraper.imagecleaner import display_image_cleaner`\n",
        "  - Once you run it, you can call `display_image_clenaer`\n",
        "  - *YOU HAVE TO RELOAD* the UI when you make different `display_image_cleaner`\n",
        "- If you click `delete` button, the image file will be moved to `DEL_DIR`, which is in default `images/deleted` \n",
        "- After the cleaning YOU HAVE TO SAVE YOUR RESULT by running the cell below.\n",
        "- Evaluation Criteria:\n",
        "  1. How did you define the rule to ommit certain examples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gYKVtXT1xgM"
      },
      "source": [
        "#### Cleaner code (run it without opening it)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqQ3uhxLTNxl"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from pathlib import Path\n",
        "from PIL import Image as PImage\n",
        "from PIL import ImageDraw as PImageDraw\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "\n",
        "##########################################################################################\n",
        "# globals & event handlers\n",
        "##########################################################################################\n",
        "ICLN_BATCH_SZ = 8\n",
        "\n",
        "# this may look nauseating and but creating new widgets is literally about 10x slower than \n",
        "# updating existing ones so the ui gets created once and updated forever more\n",
        "icln_base_path = None\n",
        "icln_folder = None\n",
        "icln_batches = None\n",
        "icln_pager = None\n",
        "icln_grid = None\n",
        "icln_empty_folder = None\n",
        "\n",
        "def delete_on_click(btn):\n",
        "  fn, img, batch, idx = btn.tag\n",
        "  img.value = icln_deleted_img() # display red 'deleted' cross\n",
        "  icln_batches[batch][idx] = \"\"  # so we know it's deleted as we page back & forth\n",
        "  btn.disabled = True\n",
        "  # try:    Path(fn).unlink()      # dbl-clicks result in us trying to delete twice\n",
        "  try: shutil.move(str(fn), DEL_DIR)\n",
        "  except Exception as e: print(e)\n",
        "\n",
        "def paging_on_click(btn):\n",
        "  folder, batch = btn.tag\n",
        "  icln_render_batch(folder, batch)\n",
        "\n",
        "def reload_on_click(btn):\n",
        "  icln_render_batch(icln_folder, 0, force_reload=True)\n",
        "\n",
        "def folder_on_change(change):\n",
        "  if(change[\"type\"] == \"change\" and change[\"name\"] == \"value\"):\n",
        "    icln_render_batch(change[\"new\"], 0)\n",
        "  \n",
        "##########################################################################################\n",
        "# UI creation\n",
        "##########################################################################################\n",
        "def icln_deleted_img():\n",
        "  # creates the red \"deleted\" placeholder cross and caches it\n",
        "  DELETED_IMG = \"deleted_img\"\n",
        "  \n",
        "  if(DELETED_IMG not in icln_deleted_img.__dict__):\n",
        "    img = PImage.new(\"RGB\",(150,150), color=\"white\")\n",
        "\n",
        "    draw = PImageDraw.Draw(img)\n",
        "    draw.line((5, 5, 140, 140), fill=\"red\", width=10)\n",
        "    draw.line((5, 140, 140, 5), fill=\"red\", width=10)\n",
        "    \n",
        "    bio = BytesIO()\n",
        "    img.save(bio, 'JPEG')\n",
        "    icln_deleted_img.__dict__[DELETED_IMG] = bio.getvalue()\n",
        "\n",
        "  return icln_deleted_img.__dict__[DELETED_IMG]\n",
        "\n",
        "def icln_create_widgets(batch_size):\n",
        "  # create the UI widgets\n",
        "  global icln_pager\n",
        "  global icln_grid\n",
        "  global icln_empty_folder\n",
        "\n",
        "  # image/delete button pairs\n",
        "  display_items = []\n",
        "  for i in range(batch_size):\n",
        "    img = widgets.Image()\n",
        "    img.layout.width=\"150px\"\n",
        "    btn = widgets.Button(description=\"Delete\")\n",
        "    btn.on_click(delete_on_click)\n",
        "    box = widgets.VBox(children=[img,btn])\n",
        "    box.layout.margin = \"5px\"\n",
        "    display_items.append(box)\n",
        "\n",
        "  # paging\n",
        "  btnFirst = widgets.Button(description=\"|<<\") \n",
        "  btnPrev = widgets.Button(description=\"<<\")\n",
        "  lblPage = widgets.Label(value=\"Page NNN of KKK\")\n",
        "  lblPage.layout = widgets.Layout(display=\"flex\", justify_content=\"center\", width=\"100px\")\n",
        "  btnNext = widgets.Button(description=\">>\")\n",
        "  btnLast = widgets.Button(description=\">>|\")\n",
        "  \n",
        "  pgbtns = [btnFirst, btnPrev, btnNext, btnLast]\n",
        "  for btn in pgbtns: btn.on_click(paging_on_click)\n",
        "  for btn in pgbtns: btn.layout.width = \"60px\"\n",
        "\n",
        "  # folder drop down\n",
        "  folders = [f.stem for f in icln_base_path.glob(\"*\") if (f.is_dir() and f.stem[0] != \".\")]\n",
        "  folders.sort()\n",
        "  rootfiles = [f for f in icln_base_path.glob(\"*.jpg\") if f.is_file()]\n",
        "  if(len(rootfiles) > 0): folders = [\"/\"] + folders\n",
        "  ddlFolder = widgets.Dropdown(options=folders, description=\"Folder: \")\n",
        "  ddlFolder.observe(folder_on_change)\n",
        "\n",
        "  # reload button\n",
        "  btnReload = widgets.Button(description=\"â†»\")\n",
        "  btnReload.layout = widgets.Layout(width=\"40px\", margin=\"0px 0px 0px 10px\")\n",
        "  btnReload.on_click(reload_on_click)\n",
        "\n",
        "  # plug it all in and display\n",
        "  icln_pager = widgets.HBox(children=[btnFirst, btnPrev, lblPage, btnNext, btnLast, \n",
        "                                      ddlFolder, btnReload])  \n",
        "  icln_grid = widgets.GridBox(display_items, \n",
        "                              layout=widgets.Layout(grid_template_columns=\"repeat(4, 25%)\",\n",
        "                                                    margin=\"15px\"))\n",
        "  icln_empty_folder = widgets.HTML(value=\"<h2>No images left to display in this folder.</h2>\")\n",
        "  icln_empty_folder.layout.visibility = \"hidden\"\n",
        "\n",
        "  display(icln_pager)\n",
        "  display(icln_empty_folder)\n",
        "  display(icln_grid)\n",
        "  \n",
        "##########################################################################################\n",
        "# UI rendering\n",
        "##########################################################################################\n",
        "def icln_render_batch(folder, batch, force_reload=False):\n",
        "  global icln_folder\n",
        "  global icln_batches\n",
        "  global icln_pager\n",
        "  global icln_grid\n",
        "\n",
        "  if(folder == \"/\"): folder = \"\"\n",
        "  path = icln_base_path/folder\n",
        "\n",
        "  if((icln_folder != folder) or (force_reload)): \n",
        "    # get the files, split into batches  \n",
        "    files = list(path.glob(\"*.jpg\"))\n",
        "    icln_batches = [files[i:i + ICLN_BATCH_SZ] for i in range(0, len(files), ICLN_BATCH_SZ)]\n",
        "    icln_folder = folder\n",
        "\n",
        "    if(len(files) == 0):\n",
        "      # fail gracefully if they've deleted every image in this folder\n",
        "      icln_empty_folder.layout.visibility = \"visible\"\n",
        "      # icln_grid.layout.visibility = \"hidden\" <-- doesn't work :-@\n",
        "      for child in icln_grid.children: child.layout.visibility = \"hidden\"\n",
        "      btnFirst, btnPrev, lblPage, btnNext, btnLast,_,_ = icln_pager.children\n",
        "      lblPage.value = \"Page 0 of 0\"\n",
        "      for btn in [btnFirst, btnPrev, btnNext, btnLast]: btn.disabled = True\n",
        "      return\n",
        "    else:\n",
        "      icln_empty_folder.layout.visibility = \"hidden\"\n",
        "      icln_grid.layout.visibility = \"visible\"\n",
        "\n",
        "  # display the images\n",
        "  for i, fp in enumerate(icln_batches[batch]):\n",
        "    icln_grid.children[i].layout.visibility = \"visible\"\n",
        "    img = icln_grid.children[i].children[0]\n",
        "    btn = icln_grid.children[i].children[1]\n",
        "\n",
        "    if(fp == \"\"):\n",
        "      img.value = icln_deleted_img()\n",
        "      btn.disabled = True\n",
        "    else:\n",
        "      img.value = open(fp, \"rb\").read()\n",
        "      btn.tag = (fp, img, batch, i)\n",
        "      btn.disabled = False\n",
        "\n",
        "  if(len(icln_batches[batch]) < ICLN_BATCH_SZ):\n",
        "    # partial batch on the last page, hide the rest of the grid\n",
        "    for i in range(len(icln_batches[batch]), ICLN_BATCH_SZ):\n",
        "      icln_grid.children[i].layout.visibility = \"hidden\"\n",
        "    \n",
        "  # update the paging controls\n",
        "  btnFirst, btnPrev, lblPage, btnNext, btnLast,_,_ = icln_pager.children\n",
        "  btnFirst.tag = (folder, 0) \n",
        "  btnPrev.tag = (folder, max(0, batch-1)) \n",
        "  btnNext.tag = (folder, min(len(icln_batches)-1, batch+1)) \n",
        "  btnLast.tag = (folder, len(icln_batches)-1) \n",
        "  lblPage.value = \"Page {} of {}\".format(batch+1, len(icln_batches))\n",
        "  for btn in [btnFirst, btnPrev, btnNext, btnLast]: btn.disabled = btn.tag[1] == batch\n",
        "\n",
        "def display_image_cleaner(path):\n",
        "    '''Display the image cleaner widget for the given folder'''\n",
        "    global icln_base_path; icln_base_path = Path(path)\n",
        "    \n",
        "    icln_create_widgets(ICLN_BATCH_SZ)\n",
        "    _,_,_,_,_,ddlFolder,_ = icln_pager.children\n",
        "    icln_render_batch(ddlFolder.value, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkZlWp1j14Mf"
      },
      "source": [
        "#### Run `display_image_cleaner`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN_6GQV3z2As"
      },
      "outputs": [],
      "source": [
        "DEL_DIR.mkdir(exist_ok=True, parents=True)\n",
        "display_image_cleaner('images/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDV76afp1c2v"
      },
      "outputs": [],
      "source": [
        "# DO NOT FORGET TO CLICK RELOAD BUTTON on the top right of the UI \n",
        "display_image_cleaner('images/valid') "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyC2J_jn9Nep"
      },
      "source": [
        "- Don't Forget to save your data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgW9IH5v9NME"
      },
      "outputs": [],
      "source": [
        "os.system(f\"zip -rq image_data_cleaned.zip {IMG_DIR}\") # Make zip file that contains images directory\n",
        "save_file(\"image_data_cleaned.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fum2E1igrY8_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM0kl91_Dzze"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-gYKVtXT1xgM"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}