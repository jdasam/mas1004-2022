{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJfE5UJca3v06/0nABK3i8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jdasam/mas1004-2022/blob/main/notebooks/Data_AI_4th_week_spiral_livecoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9O-EojgkoEZC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from math import pi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if you run this code in your local computer, you have to check that torch is installed\n",
        "!pip install torch\n",
        "# But in Google Colab, torch is already installed "
      ],
      "metadata": {
        "id": "bomZsxwfoNGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make spiral data\n",
        "# https://gist.github.com/45deg/e731d9e7f478de134def5668324c44c5\n",
        "N = 500\n",
        "theta = np.sqrt(np.random.rand(N))*2*pi # np.linspace(0,2*pi,100)\n",
        "\n",
        "r_a = 2*theta + pi\n",
        "data_a = np.array([np.cos(theta)*r_a, np.sin(theta)*r_a]).T\n",
        "x_a = data_a + np.random.randn(N,2)\n",
        "\n",
        "r_b = -2*theta - pi\n",
        "data_b = np.array([np.cos(theta)*r_b, np.sin(theta)*r_b]).T\n",
        "x_b = data_b + np.random.randn(N,2)\n",
        "\n",
        "res_a = np.append(x_a, np.zeros((N,1)), axis=1)\n",
        "res_b = np.append(x_b, np.ones((N,1)), axis=1)\n",
        "\n",
        "res = np.append(res_a, res_b, axis=0)\n",
        "np.random.shuffle(res)"
      ],
      "metadata": {
        "id": "wA2xUxDsoLzE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize_decision_boundary(model, data, label):\n",
        "  x_linspace = torch.linspace(min(data[:,0]), max(data[:,0]), steps=200)\n",
        "  y_linspace = torch.linspace(min(data[:,1]), max(data[:,1]), steps=200)\n",
        "  grid_x, grid_y = torch.meshgrid(x_linspace, y_linspace)\n",
        "  grid_xy = torch.stack([grid_x, grid_y]).permute(1,2,0)\n",
        "  grid_xy = grid_xy.view(-1, 2)\n",
        "  if isinstance(model, torch.nn.Module):\n",
        "    value_by_grid = model(grid_xy)\n",
        "  else:\n",
        "    value_by_grid = run_neuron(model, grid_xy)\n",
        "  value_by_grid = value_by_grid.view(200, 200, 1)\n",
        "  value_by_grid[value_by_grid<=0.5] = 0\n",
        "  value_by_grid[value_by_grid>0.5] = 1\n",
        "\n",
        "  plt.scatter(x=data[label[:,0]==0,0], y=data[label[:,0]==0,1])\n",
        "  plt.scatter(x=data[label[:,0]==1,0], y=data[label[:,0]==1,1])\n",
        "\n",
        "  plt.contourf(grid_x.detach().numpy(), grid_y.detach().numpy(), value_by_grid.detach().numpy().squeeze(), alpha=0.3)"
      ],
      "metadata": {
        "id": "Z-o1l0qPbMZb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's convert our data in tensor\n",
        "datas = torch.tensor(res, dtype=torch.float32)\n",
        "# represent each number with 32 bits, instead of 64 bits"
      ],
      "metadata": {
        "id": "7E-Zx8HBjh4A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datas # a tensor can only have one data type.\n",
        "# so if you want to represent float data\n",
        "# you have to represent even integer in float"
      ],
      "metadata": {
        "id": "SCeh8daDjroy",
        "outputId": "0eb8bd28-c789-4acf-fa4b-d8ba7a10c858",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -6.2360,  13.0651,   1.0000],\n",
              "        [  5.7898, -10.7633,   0.0000],\n",
              "        [  7.8541,   8.6649,   1.0000],\n",
              "        ...,\n",
              "        [ -1.8618,  13.8850,   1.0000],\n",
              "        [  6.3059,  -7.0654,   1.0000],\n",
              "        [  3.9719,   0.2770,   0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas[datas[:,-1]==0]"
      ],
      "metadata": {
        "id": "WBfdHqHgkD1d",
        "outputId": "dd1b9bf3-bf06-4c79-e2b9-1b316504c81e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  5.7898, -10.7633,   0.0000],\n",
              "        [ -8.5410,   0.1941,   0.0000],\n",
              "        [  6.4224, -11.1031,   0.0000],\n",
              "        ...,\n",
              "        [ -8.9839,  -2.3756,   0.0000],\n",
              "        [  1.4697,   6.6988,   0.0000],\n",
              "        [  3.9719,   0.2770,   0.0000]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_xy = datas[:, :2]\n",
        "data_label= datas[:, -1]"
      ],
      "metadata": {
        "id": "vnUXwvPFlUcD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_xy, data_label[:10]"
      ],
      "metadata": {
        "id": "ANeki4J5lap4",
        "outputId": "d9dd0851-6803-40cb-eb41-0193449709c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ -6.2360,  13.0651],\n",
              "         [  5.7898, -10.7633],\n",
              "         [  7.8541,   8.6649],\n",
              "         ...,\n",
              "         [ -1.8618,  13.8850],\n",
              "         [  6.3059,  -7.0654],\n",
              "         [  3.9719,   0.2770]]),\n",
              " tensor([1., 0., 1., 1., 1., 1., 1., 0., 0., 0.]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to make a tensor in specific shape\n",
        "# Let's make 2 x 3 tensor\n",
        "print(torch.zeros(2,3))\n",
        "print(torch.ones(2,3))\n",
        "print(torch.rand(2,3)) # every element will have random value between 0-1\n",
        "print(torch.randn(2,3)) # this uses gaussian (normal) distribution\n",
        " "
      ],
      "metadata": {
        "id": "1E_hxsbJmPsj",
        "outputId": "d4d25e45-89b7-4715-9a4d-b39fc5f6ed3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0.3160, 0.0010, 0.7059],\n",
            "        [0.6224, 0.5211, 0.8376]])\n",
            "tensor([[-2.0365, -1.5972,  1.4659],\n",
            "        [-0.3311,  1.0453, -0.1468]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a neural network layer\n",
        "\n",
        "\n",
        "class Layer:\n",
        "  def __init__(self, in_features, num_neurons):\n",
        "    # in_features: how many features does this layer take as an input\n",
        "    # \n",
        "    self.in_features = in_features\n",
        "    self.num_neurons = num_neurons\n",
        "\n",
        "    # next step: define a weight matrix\n",
        "    self.weight = torch.randn(self.in_features, self.num_neurons)\n",
        "    # there are two types of parameters\n",
        "    self.bias = torch.randn(self.num_neurons)\n",
        "\n",
        "  def __call__(self, input):\n",
        "    return torch.mm(input, self.weight) + self.bias\n",
        "\n",
        "layer = Layer(2, 4)\n",
        "layer.weight, layer.bias\n",
        "asingle_data = data_xy[:1]\n",
        "layer(asingle_data)"
      ],
      "metadata": {
        "id": "HUf4zt2QkM17",
        "outputId": "63371f12-b929-4d58-bb14-4327cb8c7bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-36.5538,  -0.5213,  -1.6657,  32.5262]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.mm(asingle_data, layer.weight))\n",
        "print(layer.bias)"
      ],
      "metadata": {
        "id": "JDHvG2jF38l9",
        "outputId": "167e84e8-74a3-4205-a668-49316ab07830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-10.1124, -17.8197,   3.6596,   4.7405]])\n",
            "tensor([ 0.0191, -0.3798, -0.4291,  0.2112])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_xy.shape, layer.weight.shape"
      ],
      "metadata": {
        "id": "uF5T5n9nnwRA",
        "outputId": "e197dbec-f2d2-4785-8209-73eeacf75487",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1000, 2]), torch.Size([2, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement layer's computation with pure for-loop\n",
        "\n",
        "# what will be the output's size\n",
        "output = torch.zeros(data_xy.shape[0], layer.weight.shape[1])\n",
        "\n",
        "for data_idx, data_sample in enumerate(data_xy):\n",
        "  for neuron_idx in range(layer.weight.shape[1]):\n",
        "    temporary_sum = 0\n",
        "    for feature_idx in range(len(data_sample)):\n",
        "      data_pos = data_sample[feature_idx]\n",
        "      corresp_neuron_weight = layer.weight[feature_idx, neuron_idx]\n",
        "      temporary_sum += data_pos * corresp_neuron_weight\n",
        "    # print(data_sample[i])\n",
        "    output[data_idx, neuron_idx] = temporary_sum "
      ],
      "metadata": {
        "id": "CfzA-yo1n6ep"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "id": "IuyUNqsvqPH8",
        "outputId": "8e552058-aa91-4f40-e86f-fd7ff90ad64d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.3607, -9.3477, -2.8790,  7.5625],\n",
              "        [-4.1856,  8.0268,  3.0944, -5.9477],\n",
              "        [23.5946, -0.2093, 11.3684, 10.2044],\n",
              "        ...,\n",
              "        [14.4611, -7.5534,  2.2177, 10.0994],\n",
              "        [ 1.3010,  6.5207,  4.8056, -2.8201],\n",
              "        [ 6.7673,  1.8522,  4.4839,  1.9365]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Easier, and more efficient way\n",
        "torch.mm(data_xy, layer.weight) # mm means matrix multiplication"
      ],
      "metadata": {
        "id": "QOaln0x1qSr6",
        "outputId": "df23d950-9a39-42e7-b02e-e25b97396c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.3607, -9.3477, -2.8790,  7.5625],\n",
              "        [-4.1856,  8.0268,  3.0944, -5.9477],\n",
              "        [23.5946, -0.2093, 11.3684, 10.2044],\n",
              "        ...,\n",
              "        [14.4611, -7.5534,  2.2177, 10.0994],\n",
              "        [ 1.3010,  6.5207,  4.8056, -2.8201],\n",
              "        [ 6.7673,  1.8522,  4.4839,  1.9365]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# computation time with for loop vs matrix multiplication\n",
        "import time\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "output = torch.zeros(data_xy.shape[0], layer.weight.shape[1])\n",
        "for data_idx, data_sample in enumerate(data_xy):\n",
        "  for neuron_idx in range(layer.weight.shape[1]):\n",
        "    temporary_sum = 0\n",
        "    for feature_idx in range(len(data_sample)):\n",
        "      data_pos = data_sample[feature_idx]\n",
        "      corresp_neuron_weight = layer.weight[feature_idx, neuron_idx]\n",
        "      temporary_sum += data_pos * corresp_neuron_weight\n",
        "    # print(data_sample[i])\n",
        "    output[data_idx, neuron_idx] = temporary_sum\n",
        "\n",
        "end_time = time.time()\n",
        "print(\"time spent: \", end_time - start_time) "
      ],
      "metadata": {
        "id": "icmgn9ntqzYu",
        "outputId": "0d751962-47a3-4a42-8443-19e3aff1f8d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time spent:  0.1337108612060547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Never tries to use for loop in matrix multiplication\n",
        "# matrix multiplication is much much faster than for loop\n",
        "\n",
        "start_time = time.time()\n",
        "torch.mm(data_xy, layer.weight)\n",
        "end_time = time.time()\n",
        "print(end_time - start_time)"
      ],
      "metadata": {
        "id": "rrw_jU9XrSOf",
        "outputId": "af71d86c-28cd-4f11-d51c-33771028dbb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0016651153564453125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(x):\n",
        "  # x is an tensor\n",
        "  is_larger_than_zero = x > 0\n",
        "  new_x = torch.clone(x)\n",
        "  new_x[~is_larger_than_zero] = 0\n",
        "  # print(is_larger_than_zero.shape, x.shape)\n",
        "  # the index of tensor can have the same shape with the tensor itself\n",
        "  return new_x\n",
        "relu(output)"
      ],
      "metadata": {
        "id": "z5cdTkEbs5vc",
        "outputId": "05e8a6b9-5d4e-46b5-a754-fc30b54dc16e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6.3607,  0.0000,  0.0000,  7.5625],\n",
              "        [ 0.0000,  8.0268,  3.0944,  0.0000],\n",
              "        [23.5946,  0.0000, 11.3684, 10.2044],\n",
              "        ...,\n",
              "        [14.4611,  0.0000,  2.2177, 10.0994],\n",
              "        [ 1.3010,  6.5207,  4.8056,  0.0000],\n",
              "        [ 6.7673,  1.8522,  4.4839,  1.9365]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output > 0\n"
      ],
      "metadata": {
        "id": "coYA4qWhtHSE",
        "outputId": "aab28743-b167-4f6d-e5e9-95c100821c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True, False,  True,  True],\n",
              "        [ True,  True, False, False],\n",
              "        [ True, False, False, False],\n",
              "        ...,\n",
              "        [ True, False,  True,  True],\n",
              "        [ True, False, False, False],\n",
              "        [False,  True, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_0 = Layer(in_features=2, num_neurons=4)\n",
        "layer_1 = Layer(in_features=4, num_neurons=1)\n",
        "\n",
        "print(data_xy.shape)\n",
        "out_0 = layer_0(data_xy)\n",
        "print(out_0.shape)\n",
        "out_1 = layer_1(relu(out_0))\n",
        "print(out_1.shape)"
      ],
      "metadata": {
        "id": "cdLoc1TUrtSY",
        "outputId": "a0cc76fa-6f8b-40b6-d65b-9c0159680332",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 2])\n",
            "torch.Size([1000, 4])\n",
            "torch.Size([1000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# scientific notation\n",
        "# 9.4111e-01 means 9.4111 * 10 ** (-1), 0.94111\n",
        "\n",
        "# turn off scientific notation\n",
        "torch.set_printoptions(sci_mode=False)"
      ],
      "metadata": {
        "id": "OiAobuHgsOnV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_1.shape"
      ],
      "metadata": {
        "id": "28bMH8fauN6d",
        "outputId": "7d6f6323-38b9-4e71-f00e-cebc5e2ba4ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# flattening, or squeezing the tensor\n",
        "out_1[:, 0].shape # if you select only one index in a certain dimension,\n",
        "# it will delete that dimension \n"
      ],
      "metadata": {
        "id": "6GzXuxkDuaBn",
        "outputId": "de748add-b5fe-40a9-c614-6e5eb358c1ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1000])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_1.squeeze() # this deletes every dimension with size 1"
      ],
      "metadata": {
        "id": "i973KSBSulNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's suppose that out_1 is our model's prediction for a given input\n",
        "# out_1[n] is the prediction value of whether the n-th input data is category 1\n",
        "\n",
        "# our target value is data_label\n",
        "data_label"
      ],
      "metadata": {
        "id": "BtoZ1hk6ut5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's define how bad our model is.\n",
        "pred = out_1.squeeze()\n",
        "\n",
        "pred[:10], data_label[:10]\n",
        "print(pred[:10].shape, data_label[:10].shape)\n",
        "diff = pred[:5] - data_label[:7]\n",
        "print(pred[:5], '\\n',data_label[:5],'\\n', diff)"
      ],
      "metadata": {
        "id": "tJEK5kj-vFXV",
        "outputId": "064c8f7b-843d-40d8-b621-da91e8b3fac4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10]) torch.Size([10])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ec1bc6b08a8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (7) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can make + - computation with tensor of different size\n",
        "pred[:10].shape, data_label[0:1].shape\n",
        "print(pred[:10])\n",
        "print(data_label[0:1])\n",
        "print(pred[:10] - data_label[0:1]) # It automatically broadcast \n",
        "# So you can add a scalar value to vector like this\n"
      ],
      "metadata": {
        "id": "JKhDWDUT1Sv1",
        "outputId": "21ffca40-ccbc-44a6-b4d3-0af44e439d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([16.1975, -3.1294,  2.0876,  1.4890, 19.4938, 19.1547, -1.9991,  9.0167,\n",
            "        -3.1715,  4.7047])\n",
            "tensor([1.])\n",
            "tensor([15.1975, -4.1294,  1.0876,  0.4890, 18.4938, 18.1547, -2.9991,  8.0167,\n",
            "        -4.1715,  3.7047])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How we define the loss function\n",
        "loss = torch.abs(pred - data_label) # abs means absolute value"
      ],
      "metadata": {
        "id": "vmXMoVNn2rbl"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss[:10] # each data sample has different loss "
      ],
      "metadata": {
        "id": "kSTN6w824pZY",
        "outputId": "142d7c93-05ac-4ae7-b7ee-ee2bc6dbca1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15.1975,  3.1294,  1.0876,  0.4890, 18.4938, 18.1547,  2.9991,  9.0167,\n",
              "         3.1715,  4.7047])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_mean = sum(loss) / len(loss)\n",
        "loss_mean"
      ],
      "metadata": {
        "id": "a5TeOb0N42fK",
        "outputId": "5839b06e-5356-49fd-cdb3-a96531d72655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.9336)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# in torch you can use a predefined method for tensor\n",
        "loss_mean = loss.mean()\n",
        "loss_mean, len(loss)\n",
        "\n",
        "# our goal is to reduce this loss by updating the parameters of the model\n",
        "# the model consists of two layers, currently\n"
      ],
      "metadata": {
        "id": "gBNBl_b65IzW",
        "outputId": "fb46d5e6-31df-4733-a90f-c79a796ac939",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5.9336), 1000)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the loss value will be different everytime\n",
        "# because the weights are initialized in a random way\n",
        "layer_0 = Layer(in_features=2, num_neurons=4)\n",
        "layer_1 = Layer(in_features=4, num_neurons=1)\n",
        "\n",
        "def get_loss(layer_0, layer_1, data_xy, data_label):\n",
        "  pred = layer_1(relu(layer_0(data_xy)))\n",
        "  loss_mean = torch.abs(pred-data_label).mean()\n",
        "  return loss_mean\n",
        "\n",
        "get_loss(layer_0, layer_1, data_xy, data_label)"
      ],
      "metadata": {
        "id": "lhKcPjTT5ocO",
        "outputId": "cbb0a196-ee1f-4944-cf9d-edd1a49e319f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16.8463)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What happens if we change a little bit of parameters\n",
        "selected_weight = layer_0.weight[0, 0]\n",
        "selected_weight \n",
        "# get_loss(layer_0, layer_1, data_xy, data_label)"
      ],
      "metadata": {
        "id": "hI-FCHtu5-cH",
        "outputId": "de5817bf-f6a8-4ac6-f3cc-c3fc228436ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.3554)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy \n",
        "old_loss = get_loss(layer_0, layer_1, data_xy, data_label)\n",
        "\n",
        "num_iteration = 100\n",
        "\n",
        "# this is gradient descent with single neuron\n",
        "# it only works with a single weight\n",
        "for i in range(num_iteration):\n",
        "  # change a little bit for the selected weight to calculate gradient\n",
        "  eps = 0.001\n",
        "  new_layer_0 = copy.deepcopy(layer_0)\n",
        "  new_layer_0.weight[0, 0] += eps\n",
        "  new_layer_0.weight[0, 1] += eps\n",
        "  new_loss = get_loss(new_layer_0, layer_1, data_xy, data_label)\n",
        "\n",
        "  loss_diff = new_loss - old_loss\n",
        "  gradient = loss_diff / eps\n",
        "  gradient # how the loss will change if you change the parameter for 1\n",
        "\n",
        "  # update parameters\n",
        "  learning_rate = 0.001\n",
        "  layer_0.weight[0, 0] -= gradient * learning_rate\n",
        "  new_loss = get_loss(layer_0, layer_1, data_xy, data_label)\n",
        "  print(new_loss)"
      ],
      "metadata": {
        "id": "8Nu4fBAY6bi-",
        "outputId": "e1bcc1ed-772c-4ca3-9350-0601ad615413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(16.8462)\n",
            "tensor(16.8462)\n",
            "tensor(16.8462)\n",
            "tensor(16.8462)\n",
            "tensor(16.8462)\n",
            "tensor(16.8462)\n",
            "tensor(16.8461)\n",
            "tensor(16.8461)\n",
            "tensor(16.8461)\n",
            "tensor(16.8460)\n",
            "tensor(16.8460)\n",
            "tensor(16.8460)\n",
            "tensor(16.8459)\n",
            "tensor(16.8459)\n",
            "tensor(16.8458)\n",
            "tensor(16.8457)\n",
            "tensor(16.8457)\n",
            "tensor(16.8456)\n",
            "tensor(16.8455)\n",
            "tensor(16.8454)\n",
            "tensor(16.8453)\n",
            "tensor(16.8452)\n",
            "tensor(16.8450)\n",
            "tensor(16.8449)\n",
            "tensor(16.8447)\n",
            "tensor(16.8445)\n",
            "tensor(16.8443)\n",
            "tensor(16.8441)\n",
            "tensor(16.8438)\n",
            "tensor(16.8435)\n",
            "tensor(16.8432)\n",
            "tensor(16.8428)\n",
            "tensor(16.8424)\n",
            "tensor(16.8419)\n",
            "tensor(16.8414)\n",
            "tensor(16.8409)\n",
            "tensor(16.8402)\n",
            "tensor(16.8395)\n",
            "tensor(16.8387)\n",
            "tensor(16.8379)\n",
            "tensor(16.8369)\n",
            "tensor(16.8358)\n",
            "tensor(16.8346)\n",
            "tensor(16.8332)\n",
            "tensor(16.8317)\n",
            "tensor(16.8299)\n",
            "tensor(16.8280)\n",
            "tensor(16.8259)\n",
            "tensor(16.8235)\n",
            "tensor(16.8209)\n",
            "tensor(16.8180)\n",
            "tensor(16.8148)\n",
            "tensor(16.8112)\n",
            "tensor(16.8071)\n",
            "tensor(16.8023)\n",
            "tensor(16.7966)\n",
            "tensor(16.7899)\n",
            "tensor(16.7819)\n",
            "tensor(16.7725)\n",
            "tensor(16.7615)\n",
            "tensor(16.7486)\n",
            "tensor(16.7337)\n",
            "tensor(16.7164)\n",
            "tensor(16.6967)\n",
            "tensor(16.6750)\n",
            "tensor(16.6516)\n",
            "tensor(16.6257)\n",
            "tensor(16.5968)\n",
            "tensor(16.5645)\n",
            "tensor(16.5279)\n",
            "tensor(16.4868)\n",
            "tensor(16.4414)\n",
            "tensor(16.3944)\n",
            "tensor(16.3446)\n",
            "tensor(16.2908)\n",
            "tensor(16.2317)\n",
            "tensor(16.1668)\n",
            "tensor(16.0958)\n",
            "tensor(16.0182)\n",
            "tensor(15.9332)\n",
            "tensor(15.8402)\n",
            "tensor(15.7398)\n",
            "tensor(15.6310)\n",
            "tensor(15.5144)\n",
            "tensor(15.3892)\n",
            "tensor(15.2558)\n",
            "tensor(15.1181)\n",
            "tensor(14.9771)\n",
            "tensor(14.8301)\n",
            "tensor(14.6811)\n",
            "tensor(14.5350)\n",
            "tensor(14.3953)\n",
            "tensor(14.2724)\n",
            "tensor(14.1699)\n",
            "tensor(14.0905)\n",
            "tensor(14.0371)\n",
            "tensor(14.0132)\n",
            "tensor(14.0269)\n",
            "tensor(14.0807)\n",
            "tensor(14.1716)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_0.weight.requires_grad = True\n",
        "layer_0.bias.requires_grad = True\n",
        "layer_1.weight.requires_grad = True\n",
        "layer_1.bias.requires_grad = True\n",
        "\n",
        "new_loss = get_loss(layer_0, layer_1, data_xy, data_label)\n",
        "new_loss.backward() # do backpropagation"
      ],
      "metadata": {
        "id": "CrYV1QWNCmlb"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_0.weight.data, layer_0.weight.grad"
      ],
      "metadata": {
        "id": "DyGT8khEC53V",
        "outputId": "d30e68cc-0e5a-4d59-dffb-89f8aa5b8ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[48.3523, -1.1030, -0.9030,  0.7895],\n",
              "         [-0.8538,  1.6361, -0.2767, -1.9903]]),\n",
              " tensor([[ 0.0426, -0.8905, -0.8941, -0.8194],\n",
              "         [ 0.1762,  1.2960,  1.4890, -4.8787]]))"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "  new_loss = get_loss(layer_0, layer_1, data_xy, data_label)\n",
        "  new_loss.backward()\n",
        "\n",
        "  layer_0.weight.data -= layer_0.weight.grad * learning_rate\n",
        "  layer_0.weight.grad = None\n",
        "  print(new_loss)"
      ],
      "metadata": {
        "id": "tCCyclHnDDrs",
        "outputId": "960f3cf1-ea1f-4acd-8c64-c795d45916bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14.1116, grad_fn=<MeanBackward0>)\n",
            "tensor(14.0218, grad_fn=<MeanBackward0>)\n",
            "tensor(13.9920, grad_fn=<MeanBackward0>)\n",
            "tensor(13.9621, grad_fn=<MeanBackward0>)\n",
            "tensor(13.9323, grad_fn=<MeanBackward0>)\n",
            "tensor(13.9024, grad_fn=<MeanBackward0>)\n",
            "tensor(13.8726, grad_fn=<MeanBackward0>)\n",
            "tensor(13.8427, grad_fn=<MeanBackward0>)\n",
            "tensor(13.8127, grad_fn=<MeanBackward0>)\n",
            "tensor(13.7827, grad_fn=<MeanBackward0>)\n",
            "tensor(13.7527, grad_fn=<MeanBackward0>)\n",
            "tensor(13.7227, grad_fn=<MeanBackward0>)\n",
            "tensor(13.6928, grad_fn=<MeanBackward0>)\n",
            "tensor(13.6628, grad_fn=<MeanBackward0>)\n",
            "tensor(13.6327, grad_fn=<MeanBackward0>)\n",
            "tensor(13.6027, grad_fn=<MeanBackward0>)\n",
            "tensor(13.5727, grad_fn=<MeanBackward0>)\n",
            "tensor(13.5428, grad_fn=<MeanBackward0>)\n",
            "tensor(13.5128, grad_fn=<MeanBackward0>)\n",
            "tensor(13.4830, grad_fn=<MeanBackward0>)\n",
            "tensor(13.4532, grad_fn=<MeanBackward0>)\n",
            "tensor(13.4233, grad_fn=<MeanBackward0>)\n",
            "tensor(13.3932, grad_fn=<MeanBackward0>)\n",
            "tensor(13.3631, grad_fn=<MeanBackward0>)\n",
            "tensor(13.3331, grad_fn=<MeanBackward0>)\n",
            "tensor(13.3029, grad_fn=<MeanBackward0>)\n",
            "tensor(13.2728, grad_fn=<MeanBackward0>)\n",
            "tensor(13.2425, grad_fn=<MeanBackward0>)\n",
            "tensor(13.2122, grad_fn=<MeanBackward0>)\n",
            "tensor(13.1820, grad_fn=<MeanBackward0>)\n",
            "tensor(13.1518, grad_fn=<MeanBackward0>)\n",
            "tensor(13.1216, grad_fn=<MeanBackward0>)\n",
            "tensor(13.0914, grad_fn=<MeanBackward0>)\n",
            "tensor(13.0614, grad_fn=<MeanBackward0>)\n",
            "tensor(13.0313, grad_fn=<MeanBackward0>)\n",
            "tensor(13.0012, grad_fn=<MeanBackward0>)\n",
            "tensor(12.9711, grad_fn=<MeanBackward0>)\n",
            "tensor(12.9409, grad_fn=<MeanBackward0>)\n",
            "tensor(12.9108, grad_fn=<MeanBackward0>)\n",
            "tensor(12.8806, grad_fn=<MeanBackward0>)\n",
            "tensor(12.8505, grad_fn=<MeanBackward0>)\n",
            "tensor(12.8205, grad_fn=<MeanBackward0>)\n",
            "tensor(12.7905, grad_fn=<MeanBackward0>)\n",
            "tensor(12.7605, grad_fn=<MeanBackward0>)\n",
            "tensor(12.7304, grad_fn=<MeanBackward0>)\n",
            "tensor(12.7003, grad_fn=<MeanBackward0>)\n",
            "tensor(12.6702, grad_fn=<MeanBackward0>)\n",
            "tensor(12.6402, grad_fn=<MeanBackward0>)\n",
            "tensor(12.6101, grad_fn=<MeanBackward0>)\n",
            "tensor(12.5801, grad_fn=<MeanBackward0>)\n",
            "tensor(12.5501, grad_fn=<MeanBackward0>)\n",
            "tensor(12.5200, grad_fn=<MeanBackward0>)\n",
            "tensor(12.4897, grad_fn=<MeanBackward0>)\n",
            "tensor(12.4590, grad_fn=<MeanBackward0>)\n",
            "tensor(12.4284, grad_fn=<MeanBackward0>)\n",
            "tensor(12.3977, grad_fn=<MeanBackward0>)\n",
            "tensor(12.3671, grad_fn=<MeanBackward0>)\n",
            "tensor(12.3364, grad_fn=<MeanBackward0>)\n",
            "tensor(12.3057, grad_fn=<MeanBackward0>)\n",
            "tensor(12.2751, grad_fn=<MeanBackward0>)\n",
            "tensor(12.2445, grad_fn=<MeanBackward0>)\n",
            "tensor(12.2138, grad_fn=<MeanBackward0>)\n",
            "tensor(12.1834, grad_fn=<MeanBackward0>)\n",
            "tensor(12.1531, grad_fn=<MeanBackward0>)\n",
            "tensor(12.1230, grad_fn=<MeanBackward0>)\n",
            "tensor(12.0928, grad_fn=<MeanBackward0>)\n",
            "tensor(12.0627, grad_fn=<MeanBackward0>)\n",
            "tensor(12.0327, grad_fn=<MeanBackward0>)\n",
            "tensor(12.0030, grad_fn=<MeanBackward0>)\n",
            "tensor(11.9732, grad_fn=<MeanBackward0>)\n",
            "tensor(11.9437, grad_fn=<MeanBackward0>)\n",
            "tensor(11.9144, grad_fn=<MeanBackward0>)\n",
            "tensor(11.8852, grad_fn=<MeanBackward0>)\n",
            "tensor(11.8560, grad_fn=<MeanBackward0>)\n",
            "tensor(11.8268, grad_fn=<MeanBackward0>)\n",
            "tensor(11.7976, grad_fn=<MeanBackward0>)\n",
            "tensor(11.7683, grad_fn=<MeanBackward0>)\n",
            "tensor(11.7391, grad_fn=<MeanBackward0>)\n",
            "tensor(11.7097, grad_fn=<MeanBackward0>)\n",
            "tensor(11.6804, grad_fn=<MeanBackward0>)\n",
            "tensor(11.6513, grad_fn=<MeanBackward0>)\n",
            "tensor(11.6222, grad_fn=<MeanBackward0>)\n",
            "tensor(11.5931, grad_fn=<MeanBackward0>)\n",
            "tensor(11.5642, grad_fn=<MeanBackward0>)\n",
            "tensor(11.5354, grad_fn=<MeanBackward0>)\n",
            "tensor(11.5067, grad_fn=<MeanBackward0>)\n",
            "tensor(11.4783, grad_fn=<MeanBackward0>)\n",
            "tensor(11.4500, grad_fn=<MeanBackward0>)\n",
            "tensor(11.4219, grad_fn=<MeanBackward0>)\n",
            "tensor(11.3938, grad_fn=<MeanBackward0>)\n",
            "tensor(11.3655, grad_fn=<MeanBackward0>)\n",
            "tensor(11.3372, grad_fn=<MeanBackward0>)\n",
            "tensor(11.3090, grad_fn=<MeanBackward0>)\n",
            "tensor(11.2809, grad_fn=<MeanBackward0>)\n",
            "tensor(11.2528, grad_fn=<MeanBackward0>)\n",
            "tensor(11.2246, grad_fn=<MeanBackward0>)\n",
            "tensor(11.1965, grad_fn=<MeanBackward0>)\n",
            "tensor(11.1683, grad_fn=<MeanBackward0>)\n",
            "tensor(11.1401, grad_fn=<MeanBackward0>)\n",
            "tensor(11.1118, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    }
  ]
}