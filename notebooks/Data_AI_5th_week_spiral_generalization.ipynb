{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tkh7cNjCkn5V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from math import pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THxLbrwQkn5V"
      },
      "outputs": [],
      "source": [
        "# make spiral data\n",
        "# https://gist.github.com/45deg/e731d9e7f478de134def5668324c44c5\n",
        "N = 60\n",
        "noise_weight = 2\n",
        "num_test = 40\n",
        "\n",
        "theta = np.sqrt(np.random.rand(N))*2*pi # np.linspace(0,2*pi,100)\n",
        "\n",
        "r_a = 2*theta + pi\n",
        "data_a = np.array([np.cos(theta)*r_a, np.sin(theta)*r_a]).T\n",
        "x_a = data_a + np.random.randn(N,2) * noise_weight\n",
        "\n",
        "r_b = -2*theta - pi\n",
        "data_b = np.array([np.cos(theta)*r_b, np.sin(theta)*r_b]).T\n",
        "x_b = data_b + np.random.randn(N,2) * noise_weight\n",
        "\n",
        "res_a = np.append(x_a, np.zeros((N,1)), axis=1)\n",
        "res_b = np.append(x_b, np.ones((N,1)), axis=1)\n",
        "\n",
        "res = np.append(res_a, res_b, axis=0)\n",
        "np.random.shuffle(res)\n",
        "datas = torch.tensor(res, dtype=torch.float32)\n",
        "data_xy = datas[:-num_test, :2]\n",
        "data_label= datas[:-num_test, -1]\n",
        "\n",
        "# Use random label shuffle\n",
        "# rand_perm = torch.randperm(len(data_label))\n",
        "# data_label = data_label[rand_perm]\n",
        "\n",
        "test_xy = datas[-num_test:, :2]\n",
        "test_label = datas[-num_test:, -1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKONrsHjkn5W"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def visualize_decision_boundary(model, data, label):\n",
        "  x_linspace = torch.linspace(min(data[:,0]), max(data[:,0]), steps=200)\n",
        "  y_linspace = torch.linspace(min(data[:,1]), max(data[:,1]), steps=200)\n",
        "  grid_x, grid_y = torch.meshgrid(x_linspace, y_linspace)\n",
        "  grid_xy = torch.stack([grid_x, grid_y]).permute(1,2,0)\n",
        "  grid_xy = grid_xy.view(-1, 2)\n",
        "  value_by_grid = model(grid_xy)\n",
        "\n",
        "  value_by_grid = value_by_grid.view(200, 200, 1)\n",
        "  value_by_grid[value_by_grid<=0.5] = 0\n",
        "  value_by_grid[value_by_grid>0.5] = 1\n",
        "\n",
        "  plt.scatter(x=data[label[:,0]==0,0], y=data[label[:,0]==0,1])\n",
        "  plt.scatter(x=data[label[:,0]==1,0], y=data[label[:,0]==1,1])\n",
        "\n",
        "  plt.contourf(grid_x.detach().numpy(), grid_y.detach().numpy(), value_by_grid.detach().numpy().squeeze(), alpha=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OprOUAddkn5W"
      },
      "outputs": [],
      "source": [
        "plt.scatter(x=data_xy[data_label==0,0], y=data_xy[data_label==0,1])\n",
        "plt.scatter(x=data_xy[data_label==1,0], y=data_xy[data_label==1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql_rM656kn5W"
      },
      "outputs": [],
      "source": [
        "# Plot Test set\n",
        "plt.scatter(x=test_xy[test_label==0,0], y=test_xy[test_label==0,1])\n",
        "plt.scatter(x=test_xy[test_label==1,0], y=test_xy[test_label==1,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Qylb7ickn5X"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "  def __init__(self, hidden_size=32):\n",
        "    super().__init__()\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Linear(2, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),        \n",
        "        nn.Linear(hidden_size, hidden_size),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(hidden_size, 1)\n",
        "    )\n",
        "    # self.layer1 = nn.Linear(2, hidden_size) # this is same as in_features=2, out_features=4\n",
        "    # self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
        "    # self.layer3 = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, input_x): \n",
        "    # forward function is called when you give input to your model\n",
        "    # out = self.layer1(input_x)\n",
        "    # pred = self.layer3(self.layer2(out.relu()).relu())\n",
        "\n",
        "    # this will return the prediction of our model\n",
        "    # which has shape of N, 1. (N is number of data samples in input_x)\n",
        "    pred = self.layer(input_x)\n",
        "    # pred = torch.sigmoid(pred)\n",
        "    pred = pred.sigmoid()\n",
        "    return pred\n",
        "\n",
        "# Let's do the same things with torch.optim.Optimizer\n",
        "\n",
        "model = MyModel(128)\n",
        "num_iteration = 1000\n",
        "lr = 1e-3 # 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "# tell optimizer to optimize every parameters in the model\n",
        "\n",
        "# save the loss record so that we can plot it\n",
        "loss_record = []\n",
        "binary_cross_entropy_fn = nn.BCELoss()\n",
        "\n",
        "# let's train our model for a given number of steps\n",
        "for i in range(num_iteration):\n",
        "  pred = model(data_xy) # make prediction \n",
        "  # loss = torch.abs(pred[:,0]-data_label) # calculate loss for each sample\n",
        "  # let' change loss function\n",
        "  mean_loss = binary_cross_entropy_fn(pred[:,0], data_label)\n",
        "  # mean_loss = loss.mean() # take average of loss of each sample\n",
        "  # make backpropagation of loss\n",
        "  mean_loss.backward() # this will add gradient for every parameters\n",
        "  optimizer.step() # this will update every parameters in the optimizer (in the model)\n",
        "  optimizer.zero_grad() # reset the gradient of every parameters in the optimizer\n",
        "  loss_record.append(mean_loss.item())\n",
        "\n",
        "visualize_decision_boundary(model, data_xy, data_label.unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpQOy8Qbkn5X"
      },
      "outputs": [],
      "source": [
        "visualize_decision_boundary(model, test_xy, test_label.unsqueeze(1))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}